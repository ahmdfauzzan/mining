# -*- coding: utf-8 -*-
"""Analisis_Sentimen_Ulasan_Hotel_di_Google_Maps Bahasa Indo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UUome603eVtkp-MBiWcdfdfatlhlIwPV
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
sns.set_style("whitegrid")

#set warning
import warnings
warnings.filterwarnings('ignore')


pd.pandas.set_option('display.max_columns', None)

df = pd.read_csv("/content/gabungan-semua.csv", encoding='latin-1')
df.head()

df.drop(columns = ['Name', 'Date'], inplace = True)
df.columns = ['Rating', 'Review']
df.head()

# Fungsi untuk mengubah nilai yang tidak standar menjadi nilai yang diinginkan
def clean_rating(rating):
    if ',' in rating:
        return rating.replace(',', '')
    else:
        return rating

# Menggunakan fungsi clean_rating untuk membersihkan nilai 'Rating'
df['Rating'] = df['Rating'].apply(clean_rating)

# Sekarang, kita bisa menggunakan operasi untuk membuat semua rating menjadi 'float' dan kemudian mengonversinya ke integer
df['Rating'] = df['Rating'].str.replace('/5', '').astype(float).astype(int)

# Mengganti rating 4,1 dengan 4
df.loc[df['Rating'] == 41, 'Rating'] = 4

# Tampilkan DataFrame setelah perubahan
print(df)

df['Rating'].value_counts()

"""# **Jumlah Review berdasarkan score/rating**"""

import seaborn as sns
result = df.groupby(['Rating']).size()
# plot the result
sns.barplot(x = result.index, y = result.values)

"""# **Kolom Sentimen**"""

sentimen = []
for index, row in df.iterrows():
    rating = int(row['Rating'])  # Konversi nilai rating menjadi integer
    if rating > 3:
        sentimen.append(1)  # Rating 4 dan 5 dianggap positif
    else:
        sentimen.append(-1)  # Rating 1, 2, dan 3 dianggap negatif
df['sentiment'] = sentimen
df.head()

"""# **Distribusi Sentimen**"""

df_new = df[['sentiment']]
result = df_new.groupby(['sentiment']).size()
# plot the result
sns.barplot(x = result.index, y = result.values)

"""# **Tahapan Preprocessing**"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

"""**Menghapus URL dari kolom konten**"""

df['Review'] = df['Review'].str.replace('https\S+', ' ', case=False)

"""**Merubah Teks Jadi Lower Case**"""

df['Review'] = df['Review'].str.lower()

"""**Menghapus mention**"""

df['Review'] = df['Review'].str.replace('@\S+', ' ', case=False)

"""**Menghapus Hashtag**"""

df['Review'] = df['Review'].str.replace('#\S+', ' ', case=False)

"""**Menghapus next karakter**"""

df['Review'] = df['Review'].str.replace("\'\w+", ' ', case=False)

"""**Menghapus tanda baca**"""

df['Review'] = df['Review'].str.replace("[^\w\s]", ' ', case=False)

"""**Menghapus extra whitespace**"""

df['Review'] = df['Review'].str.replace("\s(2)", ' ', case=False)

"""**Tokenization**"""

# impor word_tokenize dari modul nltk
from nltk.tokenize import word_tokenize

#df['content']=df.apply(lambda row: nltk.word_tokenize(row['content']), axis=1)
from nltk.tokenize import RegexpTokenizer
regexp = RegexpTokenizer('\w+')
df['Review_token']=df['Review'].apply(regexp.tokenize)
df.head(3)

"""# **Filtering (Stopword Removal)**"""

import nltk

nltk.download('stopwords')

from nltk.corpus import stopwords

# Remove stopwords
stopwords_list = nltk.corpus.stopwords.words("indonesian")
df['Review_token'] = df['Review_token'].apply(lambda x: [item for item in x if item not in stopwords_list])
df.head(3)

"""# **Stemming sastrawi**"""

!pip install Sastrawi

# import Sastrawi package
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

# create stemmer
factory = StemmerFactory()
stemmer = factory.create_stemmer()

# Mendefinisikan fungsi untuk melakukan stemming dan mencetak kata yang sedang di-stem
def stem_and_print(tokens):
    stemmed_tokens = [stemmer.stem(token) for token in tokens]
    for original_token, stemmed_token in zip(tokens, stemmed_tokens):
        print(f"Original: {original_token} - Stemmed: {stemmed_token}")
    return stemmed_tokens

# Menggunakan fungsi stem_and_print dalam metode apply
df['stemmed'] = df['Review_token'].apply(lambda x: stem_and_print(x))

df.head(5)

df['text_string'] = df['stemmed'].apply(lambda x: ' '.join([item for item in x if len(item)>=1]))

df.head(5)

"""# **Visualizing Word Clouds**"""

!pip install wordcloud

"""**Positive Review**"""

df_p=df[df['sentiment']==1]

all_words_lem = ' '.join([word for word in df_p['text_string']])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
from wordcloud import WordCloud

wordcloud = WordCloud(background_color='white', width=800, height=500, random_state=21, max_font_size=130).generate(all_words_lem)

plt.figure(figsize=(20, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off');

"""**Negative Reviews**"""

df_neg = df[df['sentiment'] == -1]
all_words_lemneg = ' '.join([word for word in df_neg['text_string']])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
from wordcloud import WordCloud

wordcloud = WordCloud(background_color='white', width=800, height=500, random_state=21, max_font_size=130).generate(all_words_lemneg)

plt.figure(figsize=(20, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off');

# Commented out IPython magic to ensure Python compatibility.
# Basic Operation
import pandas as pd
import numpy as np

# Text Preprocessing & Cleaning
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
import re
from wordcloud import WordCloud,STOPWORDS
from nltk import SnowballStemmer


from sklearn.model_selection import train_test_split # Split Data
from imblearn.over_sampling import SMOTE # Handling Imbalanced

# Model Building
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from xgboost import XGBClassifier
from sklearn.svm import SVC


from sklearn.metrics import classification_report , confusion_matrix , accuracy_score # Performance Metrics


# Data Visualization
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
import warnings


warnings.filterwarnings('ignore')
# %matplotlib inline

X = df['Review']
y = df['sentiment']

"""# **TF-IDF**"""

tfid = TfidfVectorizer()
X_final =  tfid.fit_transform(X)

"""# **HANDLING IMBALANCE**"""

# Handling imbalanced using SMOTE
smote = SMOTE()
x_sm,y_sm = smote.fit_resample(X_final,y)

"""# **Split Data into train & test data train 90%, data tes 10%**"""

X_train , X_test , y_train , y_test = train_test_split(x_sm , y_sm , test_size=0.2,random_state=3)

"""# **MODELLING**

**Support vector machine**
"""

from sklearn.metrics import classification_report, confusion_matrix

# Membuat model SVM
svm = SVC()

# Melatih model
svm.fit(X_train, y_train)

# Memprediksi data uji
svm_prediction = svm.predict(X_test)

# Menghitung metrik evaluasi
print("Classification Report:")
print(classification_report(y_test, svm_prediction))

print("Confusion Matrix:")
print(confusion_matrix(y_test, svm_prediction))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

# Memprediksi data uji
svm_prediction = svm.predict(X_test)

# Menghitung confusion matrix
cm = confusion_matrix(y_test, svm_prediction)

# Label untuk axes
group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']
group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in cm.flatten()/np.sum(cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]
labels = np.asarray(labels).reshape(2,2)

# Membuat heatmap
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix with Labels')
plt.show()

def prediksi_sentimen_input():
    # Meminta pengguna untuk memasukkan kalimat
    kalimat = input("Masukkan kalimat yang ingin Anda uji sentimennya: ")

    # Pra-pemrosesan kalimat
    kalimat_tokens = regexp.tokenize(kalimat)
    kalimat_preprocessed = [token for token in kalimat_tokens if token not in stopwords.words("indonesian")]
    kalimat_preprocessed_str = ' '.join(kalimat_preprocessed)  # Gabungkan kata-kata menjadi sebuah string

    # Vektorisasi kalimat
    kalimat_vectorized = tfid.transform([kalimat_preprocessed_str])

    # Prediksi sentimen kalimat
    hasil_prediksi = svm.predict(kalimat_vectorized)

    # Menampilkan hasil prediksi
    if hasil_prediksi == -1:
        print("Kalimat tersebut memiliki sentimen negatif.")
    else:
        print("Kalimat tersebut memiliki sentimen positif.")

# Memanggil fungsi untuk prediksi sentimen dari input pengguna
prediksi_sentimen_input()